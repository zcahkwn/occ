# OCC Storage System - Docker API

A dockerized REST API for the OCC-based distributed file storage system. Upload and download files using probabilistic tracking with LCRS sketches.

## üöÄ Quick Start

### Using Docker Compose (Recommended)

```bash
# Build and start the service
docker-compose up -d

# Check logs
docker-compose logs -f

# Stop the service
docker-compose down
```

The API will be available at `http://localhost:5000`

### Using Docker Directly

```bash
# Build the image
docker build -t occ-storage .

# Run the container
docker run -d \
  --name occ-storage \
  -p 5000:5000 \
  -v occ_data:/data/occ_storage \
  -e NUM_NODES=5 \
  -e REPLICATION_FACTOR=3 \
  occ-storage
```

## üì° API Endpoints

### Health Check

```bash
GET /health
```

Check if the API is running:

```bash
curl http://localhost:5000/health
```

Response:
```json
{
  "status": "healthy",
  "nodes": 5,
  "ready": true
}
```

### Network Status

```bash
GET /status
```

Get detailed network statistics:

```bash
curl http://localhost:5000/status
```

Response:
```json
{
  "network": {
    "total_nodes": 5,
    "union_size": 10,
    "total_chunks": 15,
    "total_storage_mb": 3.81,
    "average_replication": 3.0,
    "level_counts": [9990, 0, 0, 10, 0, 0]
  },
  "nodes": [...],
  "config": {...},
  "files_stored": 2
}
```

### Upload File

```bash
POST /upload
```

Upload a file to the storage network:

```bash
# Using curl
curl -X POST \
  -F "file=@example.pdf" \
  -F "replication_factor=3" \
  http://localhost:5000/upload

# Using Python
import requests

with open('example.pdf', 'rb') as f:
    files = {'file': f}
    data = {'replication_factor': 3}
    response = requests.post('http://localhost:5000/upload', files=files, data=data)
    print(response.json())
```

Response:
```json
{
  "success": true,
  "file_hash": "abc123...",
  "file_name": "example.pdf",
  "file_size": 1048576,
  "chunks": 4,
  "replication_factor": 3,
  "distribution": {
    "chunk_hash1": ["node_000", "node_001", "node_002"],
    ...
  }
}
```

### Download File

```bash
GET /download/<file_hash>
```

Download a file from the storage network:

```bash
# Using curl
curl -O http://localhost:5000/download/abc123...

# Using Python
import requests

response = requests.get('http://localhost:5000/download/abc123...')
with open('downloaded_file.pdf', 'wb') as f:
    f.write(response.content)
```

### List Files

```bash
GET /files
```

List all stored files:

```bash
curl http://localhost:5000/files
```

Response:
```json
{
  "total_files": 2,
  "files": [
    {
      "file_hash": "abc123...",
      "file_name": "example.pdf",
      "file_size": 1048576,
      "chunks": 4,
      "retrievable": true,
      "min_replication": 3,
      "avg_replication": 3.0
    },
    ...
  ]
}
```

### Verify File

```bash
GET /verify/<file_hash>
```

Verify file availability and replication:

```bash
curl http://localhost:5000/verify/abc123...
```

Response:
```json
{
  "file_hash": "abc123...",
  "file_name": "example.pdf",
  "retrievable": true,
  "missing_chunks": [],
  "replication": {
    "min": 3,
    "avg": 3.0,
    "max": 3
  },
  "chunks": [...]
}
```

### Rebalance File

```bash
POST /rebalance/<file_hash>
```

Rebalance file chunks to meet replication targets:

```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"replication_factor": 4}' \
  http://localhost:5000/rebalance/abc123...
```

## üß™ Testing the API

### Automated Test Suite

Run the complete test suite:

```bash
# Make sure the API is running
docker-compose up -d

# Run tests
python test_api.py
```

### Manual Testing with curl

```bash
# 1. Check health
curl http://localhost:5000/health

# 2. Upload a file
curl -X POST -F "file=@test.txt" http://localhost:5000/upload

# 3. List files
curl http://localhost:5000/files

# 4. Download file (use hash from upload response)
curl -O http://localhost:5000/download/FILE_HASH

# 5. Verify file
curl http://localhost:5000/verify/FILE_HASH
```

### Test with Exponential Science Logo

```python
# Upload the logo
import requests

with open('occ_storage/exp.jpg', 'rb') as f:
    response = requests.post('http://localhost:5000/upload', files={'file': f})
    file_hash = response.json()['file_hash']

# Download it back
response = requests.get(f'http://localhost:5000/download/{file_hash}')
with open('retrieved_logo.jpg', 'wb') as f:
    f.write(response.content)
```

## ‚öôÔ∏è Configuration

### Environment Variables

Configure the API via environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | 5000 | API port |
| `NUM_NODES` | 5 | Number of storage nodes |
| `N_PRIME` | 10000 | LCRS sketch size |
| `TAU` | 10 | Max counter value |
| `REPLICATION_FACTOR` | 3 | Default replication factor |
| `CHUNK_SIZE` | 262144 | Chunk size in bytes (256KB) |
| `STORAGE_DIR` | /data/occ_storage | Storage directory |
| `DEBUG` | false | Enable debug mode |

### Custom Configuration

Create a `.env` file:

```env
NUM_NODES=10
N_PRIME=50000
TAU=15
REPLICATION_FACTOR=5
CHUNK_SIZE=524288
```

Then use it with docker-compose:

```bash
docker-compose --env-file .env up
```

## üèóÔ∏è Production Deployment

### With Nginx Reverse Proxy

Enable the production profile:

```bash
docker-compose --profile production up -d
```

This starts:
- OCC Storage API on port 5000 (internal)
- Nginx reverse proxy on port 80 (public)

### With HTTPS (TLS/SSL)

1. Add SSL certificates to `./certs/`
2. Update `nginx.conf` with SSL configuration
3. Update `docker-compose.yml` to mount certificates

### Scaling

For horizontal scaling:

```bash
# Run multiple API instances
docker-compose up --scale occ-storage=3

# Use a load balancer (HAProxy, Nginx, etc.)
```

## üìä Monitoring

### Health Checks

The container includes a health check that runs every 30 seconds:

```bash
docker ps
# Check HEALTH STATUS column
```

### Logs

```bash
# View logs
docker-compose logs -f occ-storage

# View last 100 lines
docker-compose logs --tail 100 occ-storage
```

### Metrics

Access network statistics:

```bash
# Get detailed metrics
curl http://localhost:5000/status | jq '.'
```

## üîí Security Considerations

1. **File Size Limits**: Configure max upload size in Nginx
2. **Authentication**: Add API key authentication for production
3. **HTTPS**: Always use HTTPS in production
4. **Rate Limiting**: Implement rate limiting to prevent abuse
5. **Input Validation**: File types and sizes are validated

## üêõ Troubleshooting

### Container won't start

```bash
# Check logs
docker-compose logs occ-storage

# Rebuild image
docker-compose build --no-cache
```

### Upload fails

```bash
# Check file size limits
# Default max is 100MB in nginx.conf

# Check available storage
docker exec occ-storage df -h /data
```

### Download fails

```bash
# Verify file exists
curl http://localhost:5000/files

# Check file availability
curl http://localhost:5000/verify/FILE_HASH
```

### Performance issues

```bash
# Increase nodes
docker-compose down
docker-compose up -d -e NUM_NODES=10

# Adjust chunk size
docker-compose up -d -e CHUNK_SIZE=524288
```

## üìö API Client Examples

### Python Client

```python
class OCCStorageClient:
    def __init__(self, base_url='http://localhost:5000'):
        self.base_url = base_url

    def upload(self, file_path, replication=3):
        with open(file_path, 'rb') as f:
            response = requests.post(
                f'{self.base_url}/upload',
                files={'file': f},
                data={'replication_factor': replication}
            )
        return response.json()

    def download(self, file_hash, output_path):
        response = requests.get(f'{self.base_url}/download/{file_hash}')
        with open(output_path, 'wb') as f:
            f.write(response.content)
        return output_path

# Usage
client = OCCStorageClient()
result = client.upload('document.pdf')
client.download(result['file_hash'], 'retrieved.pdf')
```

### JavaScript Client

```javascript
async function uploadFile(file) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('replication_factor', '3');

    const response = await fetch('http://localhost:5000/upload', {
        method: 'POST',
        body: formData
    });
    return response.json();
}

async function downloadFile(fileHash) {
    const response = await fetch(`http://localhost:5000/download/${fileHash}`);
    const blob = await response.blob();
    return blob;
}
```

## üõ†Ô∏è Development

### Local Development

```bash
# Install dependencies
pip install -r requirements-docker.txt

# Run locally
python -m occ_storage.api.app

# Run with custom config
NUM_NODES=10 python -m occ_storage.api.app
```

### Building Custom Image

```dockerfile
# Extend the base image
FROM occ-storage:latest

# Add custom modifications
RUN pip install additional-package

# Override command
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "occ_storage.api.app:app"]
```

## üìà Performance

### Benchmarks

With default configuration (5 nodes, 256KB chunks):

- **Upload Speed**: ~10MB/s
- **Download Speed**: ~50MB/s
- **Memory Usage**: ~100MB per node
- **LCRS Sketch Size**: ~10KB per node
- **Query Time**: <10ms for probabilistic routing

### Optimization Tips

1. **Increase nodes** for better distribution
2. **Adjust chunk size** based on file sizes
3. **Tune N_PRIME** for accuracy vs memory trade-off
4. **Use SSD storage** for better I/O performance
5. **Enable caching** for frequently accessed files

## üìÑ License & Credits

Based on the patented OCC (Overlapping Cardinality Computation) algorithms for distributed storage.

---

**Ready to deploy!** üöÄ The OCC Storage API provides IPFS-like functionality with enhanced privacy and efficiency through probabilistic tracking.